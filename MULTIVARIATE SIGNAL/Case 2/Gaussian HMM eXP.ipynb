{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Initial State\n",
    "        self.s_0 = nn.Parameter(torch.tensor([5.525, 5.1, 5.1,5.1], requires_grad=True)).requires_grad_(True)\n",
    "        \n",
    "        self.T = nn.Parameter(torch.tensor(torch.rand(4,4), requires_grad=True)).requires_grad_(True)\n",
    "        self.mu1 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
    "        \n",
    "        self.mu2 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
    "        \n",
    "        self.std1 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
    "        self.std2 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x,t,pred):\n",
    "\n",
    "        x = F.softmax((x.clone()),dim=0)\n",
    "        l=0.0\n",
    "        std1=torch.exp(self.std1).clip(1e-16,1)\n",
    "        std2=torch.exp(self.std2).clip(1e-16,1)\n",
    "        \n",
    "\n",
    "        x_temp=x.clone()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        dist=MultivariateNormal(self.mu1[0]+torch.exp(self.mu2[0]*(torch.tensor(0))), (std1[0])*torch.eye(length).to(device))\n",
    "        \n",
    "        o_1 = torch.exp(dist.log_prob(pred[0]))\n",
    "\n",
    "        x_temp[0]=o_1*x[0].clone()\n",
    "\n",
    "        dist=MultivariateNormal(self.mu1[1]+torch.exp(self.mu2[1]*(torch.tensor(0))),( std1[1])*torch.eye(length).to(device))\n",
    "\n",
    "        o_1 = torch.exp(dist.log_prob(pred[0]))\n",
    "        x_temp[1]=o_1.clone()*x[1].clone()\n",
    "\n",
    "        dist=MultivariateNormal(self.mu1[2]+torch.exp(self.mu2[2]*(torch.tensor(0))), (std1[2])*torch.eye(length).to(device))\n",
    "        o_1 = torch.exp(dist.log_prob(pred[0]))\n",
    "        x_temp[2]=o_1*x[2].clone()\n",
    "        \n",
    "        dist=MultivariateNormal(self.mu1[3]+torch.exp(self.mu2[3]*(torch.tensor(0))), (std1[3])*torch.eye(length).to(device))\n",
    "        o_1 = torch.exp(dist.log_prob(pred[0]))\n",
    "        x_temp[3]=o_1*x[3].clone()\n",
    "        \n",
    "#         print(x_temp)\n",
    "        \n",
    "\n",
    "\n",
    "        x_temp=x_temp.clip(1e-16,1)\n",
    "        \n",
    "        x=x_temp.clone()/torch.sum(x_temp.clone())\n",
    "        l+=torch.log(torch.sum(x_temp.clone()))# -0.01*state\n",
    "        \n",
    "        for i in range(1,t): \n",
    "\n",
    "            \n",
    "            x=torch.matmul(x,F.softmax(self.T,dim=1))\n",
    "            x_temp=x.clone()\n",
    "            \n",
    "\n",
    "            x_temp1=x.clone()\n",
    "            dist=MultivariateNormal(self.mu1[0]+torch.exp(self.mu2[0]*(torch.tensor(i))), (std1[0])*torch.eye(length).to(device))\n",
    "        \n",
    "            o_1 = torch.exp(dist.log_prob(pred[i]))\n",
    "\n",
    "            x_temp[0]=o_1*x[0].clone()\n",
    "\n",
    "            dist=MultivariateNormal(self.mu1[1]+torch.exp(self.mu2[1]*(torch.tensor(i))), (std1[1])*torch.eye(length).to(device))\n",
    "\n",
    "            o_1 = torch.exp(dist.log_prob(pred[i]))\n",
    "            x_temp[1]=o_1.clone()*x[1].clone()\n",
    "\n",
    "            dist=MultivariateNormal(self.mu1[2]+torch.exp(self.mu2[2]*(torch.tensor(i))),( std1[2])*torch.eye(length).to(device))\n",
    "            o_1 = torch.exp(dist.log_prob(pred[i]))\n",
    "            x_temp[2]=o_1*x[2].clone()\n",
    "\n",
    "            dist=MultivariateNormal(self.mu1[3]+torch.exp(self.mu2[3]*(torch.tensor(i))), (std1[3])*torch.eye(length).to(device))\n",
    "            o_1 = torch.exp(dist.log_prob(pred[i]))\n",
    "            x_temp[3]=o_1*x[3].clone()\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "#             print(x_temp)\n",
    "#             print(pred[i])\n",
    "            x_temp=x_temp.clip(1e-16,1)\n",
    "\n",
    "            x=x_temp.clone()/torch.sum(x_temp.clone())\n",
    "#             print(x)\n",
    "#             print(\"-----------------------------\")\n",
    "            l+=torch.log(torch.sum(x_temp.clone()))\n",
    "        return l\n",
    "    \n",
    "    def transition(self,x):\n",
    "        x=torch.matmul(x.to(device),F.softmax(self.T,dim=1))\n",
    "        x_temp=x.clone()\n",
    "        return x\n",
    "    def Observation(self,x):\n",
    "\n",
    "#         o_1= self.emission((x))\n",
    "#         o_1[1]=torch.exp(o_1[1])\n",
    "\n",
    "        return mu\n",
    "    \n",
    "    def simulate(self):\n",
    "         o=[]\n",
    "         x1 = 0\n",
    "         for i in range(0,1000):\n",
    "             print(x1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "             if x1==0:\n",
    "                x=torch.tensor([1.0,0.0,0]).to(device)\n",
    "             if x1==1:\n",
    "                x=torch.tensor([0, 1.0,0.0]).to(device)\n",
    "             if x1==2:\n",
    "                x=torch.tensor([0.0,0.0,1]).to(device)\n",
    "             o_1= self.emission((x)) \n",
    "             o_1=o_1/torch.sum(o_1)\n",
    "\n",
    "             o.append(torch.distributions.Categorical(o_1.to(device)).sample())\n",
    "             if x1==2:\n",
    "                \n",
    "                return o\n",
    "             x = self.transition((x))\n",
    "             x1=(torch.distributions.Categorical(x.to(device)).sample()).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7000, 0.1300, 0.1000, 0.0700],\n",
      "        [0.1000, 0.7300, 0.1000, 0.0700],\n",
      "        [0.2020, 0.2525, 0.4747, 0.0707],\n",
      "        [0.1000, 0.0700, 0.0400, 0.7900]])\n",
      "tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "T_matrix=torch.rand(3, 3).to(device)\n",
    "T_matrix=torch.tensor([[0.7000, 0.1300, 0.1000, 0.0700],\n",
    "        [0.1000, 0.7300, 0.1000, 0.0700],\n",
    "        [0.2020, 0.2525, 0.4747, 0.0707],\n",
    "        [0.1000, 0.0700, 0.0400, 0.7900]], device=device)\n",
    "\n",
    "# T_matrix[1,1]=8\n",
    "\n",
    "# T_matrix[2,2]=8\n",
    "\n",
    "# T_matrix[0,0]=8\n",
    "\n",
    "T_matrix=T_matrix/torch.sum(T_matrix, 1).reshape(4,1)\n",
    "\n",
    "\n",
    "s_0=torch.rand(3).to(device)\n",
    "\n",
    "s_0=torch.tensor([1,0,0])\n",
    "s_0=s_0/torch.sum(s_0)\n",
    "O_matrix_mean=torch.tensor([1.5,2.5,3.5,5.5]).to(device)\n",
    "O_matrix_mean1=torch.tensor([0.01,0.02,0.03,0.04]).to(device)\n",
    "O_matrix_std=torch.tensor([1.1,1.2,1.3,1.4]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(T_matrix)\n",
    "\n",
    "print(s_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_HMM(T_matrix,O_matrix,x,t):\n",
    "    x=0\n",
    "    \n",
    "    \n",
    "    t=0\n",
    "    o=[]\n",
    "#     o_1=torch.matmul(x.to(device),O_matrix.to(device))\n",
    "# #         print(o_1)\n",
    "#     o.append(Normal(O_matrix_mean[x],O_matrix_std[x]).sample().to(device))\n",
    "    \n",
    "    K=[2*i/(length) for i in range(1,length+1)]\n",
    "    K=torch.tensor(K).to(device)\n",
    "    o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )         \n",
    "    t=1\n",
    "    for i in range(1,1000):\n",
    "#         print(i)\n",
    "        x=(torch.distributions.Categorical(T_matrix[x].to(device)).sample())\n",
    "#         print(x)\n",
    "        \n",
    "        \n",
    "        t+=1\n",
    "        if x==0:\n",
    "            o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )         \n",
    "        if x==1:\n",
    "            o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(3*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )         \n",
    "        if x==2:\n",
    "            o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+(torch.exp(O_matrix_mean1[x]*torch.tensor(t)))*torch.sin(6*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )         \n",
    "        if x==3:\n",
    "            o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+(torch.exp(O_matrix_mean1[x]*torch.tensor(t)))*torch.sin(9*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )         \n",
    "        t1=t\n",
    "        if (t==50) :\n",
    "            break\n",
    "    \n",
    "    \n",
    "\n",
    "    return o,t,t1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(3*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+(torch.exp(O_matrix_mean1[x]*torch.tensor(t)))*torch.sin(6*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+(torch.exp(O_matrix_mean1[x]*torch.tensor(t)))*torch.sin(9*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([ 0.1979,  1.9243,  2.9772,  7.1350,  9.8406,  5.8789,  4.1596,  1.2357,\n",
       "           0.1411, -0.0480]),\n",
       "  tensor([ 2.5946,  1.1703,  1.9082,  6.0196,  9.1351,  6.7261,  2.8895,  2.8168,\n",
       "           0.6430, -0.2222]),\n",
       "  tensor([-0.0510,  2.1605,  4.0198,  3.0491,  7.7566,  4.9561,  0.1876,  2.9438,\n",
       "           1.0787,  0.4534]),\n",
       "  tensor([0.0251, 1.7300, 3.3036, 3.8160, 9.6802, 5.6071, 0.7935, 1.6137, 1.5774,\n",
       "          0.9456]),\n",
       "  tensor([ 2.3242,  3.0956,  0.8362,  4.1714, 10.1439,  5.0792,  2.7953,  0.3056,\n",
       "           2.4936,  0.8940]),\n",
       "  tensor([-1.1277,  1.8407,  3.7991,  3.6969, 10.2445,  4.5513,  3.9037,  0.1416,\n",
       "           2.3529,  0.4175]),\n",
       "  tensor([ 4.8116,  2.0942,  2.7510,  4.6906, 10.0919,  4.8095,  2.4970,  3.1377,\n",
       "           1.2060,  0.5455]),\n",
       "  tensor([ 1.1789, -0.1920,  1.5687,  3.6682,  8.9068,  4.7851,  3.0610,  2.1608,\n",
       "           0.6730,  2.5273]),\n",
       "  tensor([0.5112, 2.2296, 2.5282, 6.4651, 8.2043, 3.2340, 2.4622, 2.7151, 1.3262,\n",
       "          0.9175]),\n",
       "  tensor([ 2.6281,  1.3435,  3.1520,  6.5941,  8.4311,  6.0686,  2.0930,  1.0007,\n",
       "           3.6529, -1.0452]),\n",
       "  tensor([ 1.4911,  0.2902,  0.9681,  7.0201, 10.0489,  3.8088,  3.5906,  1.9458,\n",
       "          -0.8702,  0.3549]),\n",
       "  tensor([ 1.2271,  2.2275,  1.9007,  7.6364, 12.3221,  7.1033,  4.4286,  2.4520,\n",
       "          -0.6335,  0.4204]),\n",
       "  tensor([ 1.2720,  3.2142,  3.2759,  5.6170,  8.6262,  4.9945,  3.1347,  1.8713,\n",
       "           2.5727, -0.1111]),\n",
       "  tensor([ 4.0230e-03,  2.7425e+00,  3.4860e+00,  5.5659e+00,  9.5201e+00,\n",
       "           4.8849e+00,  5.1685e+00,  3.7824e+00,  3.0005e+00, -7.9109e-01]),\n",
       "  tensor([ 2.4889,  1.0637,  4.3408,  5.9217,  8.1473,  3.4865,  0.7993,  2.7640,\n",
       "           0.4777, -0.7572]),\n",
       "  tensor([ 3.8177,  2.5977,  1.6427,  7.2151, 11.8202,  6.1905,  3.0306,  1.8283,\n",
       "           0.3033,  1.1236]),\n",
       "  tensor([ 0.9411,  2.2594,  2.4346,  7.3278, 10.3012,  6.1028,  5.1664,  2.1116,\n",
       "           0.7126, -0.7242]),\n",
       "  tensor([ 1.3888,  1.5072,  3.5216,  9.0048, 10.9445,  7.8308,  4.5573,  1.8324,\n",
       "           0.9648,  0.6178]),\n",
       "  tensor([ 2.8309,  0.7727,  2.3471,  6.7376, 11.2248,  5.5882,  3.2173,  3.6615,\n",
       "           1.6650,  1.7815]),\n",
       "  tensor([-0.1025,  1.9676,  3.6464,  6.0195,  9.9654,  6.4795,  2.1390, -0.3275,\n",
       "           2.0400,  0.8856]),\n",
       "  tensor([ 0.9541,  0.3940,  2.0222,  8.1404, 11.1813,  4.4702,  2.8880,  1.8875,\n",
       "          -0.7318,  1.5629]),\n",
       "  tensor([-0.3510,  1.3242,  4.0169,  7.7241, 10.8356,  6.6836,  4.4195,  0.8288,\n",
       "           0.7690, -0.2400]),\n",
       "  tensor([ 1.9935, -0.7179,  1.3665,  6.4073, 11.4343,  4.2415,  2.8946,  1.0314,\n",
       "           1.0819, -1.8426]),\n",
       "  tensor([ 1.5935,  0.9600,  1.8903,  7.3166, 11.1510,  8.6662,  4.8145,  1.8164,\n",
       "           0.2318, -0.4068]),\n",
       "  tensor([ 2.1522,  1.3663,  4.0245,  6.7838, 10.1611,  7.0338,  3.0589,  2.5027,\n",
       "           0.7943,  0.1170]),\n",
       "  tensor([ 3.0558,  1.6703,  2.5261,  6.6756, 11.3127,  7.1709,  2.6356,  4.5164,\n",
       "           0.7674, -1.3313]),\n",
       "  tensor([0.8007, 4.5804, 2.3674, 4.6364, 6.4612, 5.0542, 2.0679, 3.6750, 0.9440,\n",
       "          0.7766]),\n",
       "  tensor([2.5416, 3.3777, 2.6151, 4.3706, 8.8066, 5.0935, 4.0560, 2.7633, 2.2060,\n",
       "          1.4466]),\n",
       "  tensor([ 2.4695, -1.7634,  0.2196,  8.7589, 13.6278,  4.7314,  5.8688,  2.9472,\n",
       "          -0.8070, -1.4296]),\n",
       "  tensor([ 0.9058,  3.3417,  5.0551,  8.4060, 11.5558,  7.6683,  2.7533,  2.7720,\n",
       "           1.4908, -0.8625]),\n",
       "  tensor([2.1834, 1.3976, 1.9557, 6.0620, 7.8978, 4.2994, 4.2714, 2.1922, 1.9306,\n",
       "          2.7503]),\n",
       "  tensor([2.4966, 2.9528, 2.4970, 4.8035, 7.9325, 3.6988, 1.8687, 3.3317, 2.1863,\n",
       "          0.4360]),\n",
       "  tensor([ 1.4452, -2.7450,  4.9249,  0.9661, 13.7488,  4.0756,  7.1477, -2.1817,\n",
       "           1.5162,  1.0411]),\n",
       "  tensor([ 1.6087, -1.9731,  4.8149,  1.7737, 14.1891,  2.8666,  7.7353, -0.3569,\n",
       "           0.7976, -0.7411]),\n",
       "  tensor([ 2.2134, -1.6750,  4.7818,  0.2823, 14.7603,  0.1590,  4.5743, -0.0905,\n",
       "           1.4175,  0.8785]),\n",
       "  tensor([ 2.0540, -3.1889,  6.3264,  1.1458, 14.2173,  1.3569,  6.1566, -1.8086,\n",
       "           2.7296,  0.9244]),\n",
       "  tensor([ 2.6487, -0.3124,  5.3666,  1.6047, 14.9039,  1.4205,  5.2547, -1.4300,\n",
       "           2.4244,  1.3662]),\n",
       "  tensor([ 3.8501,  1.0514,  5.9384,  0.6268, 14.8126, -0.4529,  4.8378, -0.9388,\n",
       "           1.9966, -0.5770]),\n",
       "  tensor([ 4.1861, -2.5935,  6.0875,  1.7973, 13.6694,  2.1929,  4.6743,  0.0845,\n",
       "           4.1926,  0.7005]),\n",
       "  tensor([ 0.8500, -1.4551,  7.1503,  2.7038, 13.6717,  0.7053,  6.7417, -1.1041,\n",
       "           3.1179,  0.4511]),\n",
       "  tensor([ 1.4441,  2.9527,  2.9014,  7.4052, 12.3493,  9.3066,  3.6947,  3.2895,\n",
       "           1.3452,  0.7787]),\n",
       "  tensor([-1.0817,  4.1708,  4.7316,  6.0523, 12.0466,  6.6570,  4.7287,  1.2058,\n",
       "           0.5694,  0.9344]),\n",
       "  tensor([ 0.5165,  1.9290,  3.5496,  5.6720, 11.7006,  5.3642,  5.8366,  1.5557,\n",
       "           1.6574, -0.5437]),\n",
       "  tensor([ 1.1723,  0.9266,  3.2380,  7.6160, 10.2707,  6.8496,  4.3194,  2.5952,\n",
       "          -0.2336,  0.6760]),\n",
       "  tensor([ 1.1619,  1.0439,  3.3579,  7.4452, 13.3638,  6.7092,  4.7883,  0.6483,\n",
       "           1.2667,  0.9858]),\n",
       "  tensor([ 3.8242, -2.9075,  8.0819,  1.4601, 16.0968, -0.6577,  7.8317, -2.1990,\n",
       "           1.7566, -1.7341]),\n",
       "  tensor([-0.5809, -3.0042,  7.6274, -0.6755, 14.3413, -0.8699,  7.2836, -4.3158,\n",
       "           1.7346,  1.3473]),\n",
       "  tensor([ 4.1029, -2.2078,  6.1454, -1.5688, 16.5949,  1.1482,  9.1462, -1.8501,\n",
       "           2.7984, -1.4386]),\n",
       "  tensor([ 1.2643, -4.5066,  6.1009, -2.1343, 18.8558, -2.5164,  8.3756, -1.1418,\n",
       "           2.0026, -0.8312]),\n",
       "  tensor([ 2.3767, -3.0643,  7.7956, -1.0216, 18.7872, -3.1495,  8.5542, -3.7713,\n",
       "           5.5946,  1.6464])],\n",
       " 50,\n",
       " 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=simulate_HMM(T_matrix,O_matrix_mean,torch.tensor([1.0,0,0.0]),1000)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def distribution_initalize(o):\n",
    "#     s=torch.zeros(10)\n",
    "#     for i in range(0,10):\n",
    "#         s[i]=torch.sum(o==i)\n",
    "        \n",
    "#     return s#/torch.sum(s)\n",
    "# def distribution_update(dist,o):\n",
    "\n",
    "#     return dist + distribution_initalize(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=distribution_initalize(o[0])\n",
    "\n",
    "def Expectation_diff(o_1):\n",
    "    return torch.sum(o_1[0])\n",
    "\n",
    "\n",
    "def abs_diff(e):\n",
    "    k=0\n",
    "    for i,e1 in enumerate(e):\n",
    "        for j,e2 in enumerate(e):\n",
    "            if j==i+1:\n",
    "                k+=torch.abs(e2-e1)\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+torch.exp(O_matrix_mean1[x]*torch.tensor(t))*torch.sin(3*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+(torch.exp(O_matrix_mean1[x]*torch.tensor(t)))*torch.sin(9*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\2232260582.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o.append(MultivariateNormal(0.1*5/(0.05+(torch.tensor(K)-1)**2)+(torch.exp(O_matrix_mean1[x]*torch.tensor(t)))*torch.sin(6*torch.pi*torch.tensor(K/2)/1),O_matrix_std[x]*torch.eye(length)).sample().to(device)   )\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\3854259573.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.T = nn.Parameter(torch.tensor(torch.rand(4,4), requires_grad=True)).requires_grad_(True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\3854259573.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.mu1 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\3854259573.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.mu2 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\3854259573.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.std1 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16260\\3854259573.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.std2 = nn.Parameter(torch.tensor(torch.rand(4,length), requires_grad=True)).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 758.6820185184479 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time\n",
    "\n",
    "start_time = time.time() \n",
    "for batch_size in [5]:\n",
    "    trial =0 \n",
    "    while trial < 5:\n",
    "        t=50\n",
    "        \n",
    "        try: \n",
    "            pred1=[]\n",
    "            for i in range(0,batch_size):\n",
    "                pred1.append(simulate_HMM(T_matrix,O_matrix_mean,s_0,t))\n",
    "            import torch.optim as optim\n",
    "            net = Net()\n",
    "            net.to(device)\n",
    "            optimizer = optim.Adam(net.parameters(), lr=.01)\n",
    "            scheduler =lr_scheduler.LinearLR(optimizer,start_factor=1, end_factor=0.001, total_iters=75)\n",
    "            net.train()\n",
    "    \n",
    "            running_loss = 0.0\n",
    "            o,t,t__1=simulate_HMM(T_matrix,O_matrix_mean,s_0,t)\n",
    "            # dist=distribution_initalize(o)\n",
    "            for epoch in range(100):  # loop over the dataset multiple times\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                # forward + backward + optimize\n",
    "    \n",
    "    \n",
    "    \n",
    "                loss=0.0\n",
    "    \n",
    "                for i in range(0,batch_size):\n",
    "                    optimizer.zero_grad()\n",
    "                    loss=0.0\n",
    "    \n",
    "            #         o,t=simulate_HMM(T_matrix,O_matrix_mean,s_0,t)\n",
    "                    o,t,t_11=pred1[i]\n",
    "                    pred=torch.zeros((1,t), dtype=torch.int32)\n",
    "                    pred=o\n",
    "            #         dist=distribution_update(dist,o)\n",
    "                    loss-=net(net.s_0,t,pred)\n",
    "                   \n",
    "    \n",
    "    \n",
    "                    #+ l1_reg*l1_lambda\n",
    "                #     print(loss)\n",
    "                    loss=loss #+ 10*(torch.sum(t1*t2)/((torch.sum(t1**2)**0.5)*torch.sum(t2**2)**0.5) +torch.sum(t3*t2)/((torch.sum(t3**2)**0.5)*torch.sum(t2**2)**0.5)+torch.sum(t1*t3)/((torch.sum(t1**2)**0.5)*torch.sum(t3**2)**0.5) )\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "                    # print statistics\n",
    "            # print(f'[{trial + 1}] loss: {loss/t}')\n",
    "    \n",
    "            # print('Finished Training')\n",
    "    \n",
    "            torch.save(pred1, \"data_normal\\ \"+str(batch_size)+\"_ee_\"+ str(trial)+ \"_data.pt\")\n",
    "            torch.save(net.state_dict(),  \"Model_normal\\ \" +str(batch_size)+\"_ee_\"+ str(trial)+ \"_model.pth\")\n",
    "            trial+=1\n",
    "        except:\n",
    "            print(f'[{trial + 1}] loss: {loss/t}')\n",
    "            \n",
    "            \n",
    "            pass\n",
    "end_time = time.time()  # Capture end time after the loop completes\n",
    "\n",
    "print(f\"Total execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
